{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import ast\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "#Linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#RF\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Metrics\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#feature selection\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#Gradient Boosting \n",
    "#lightgbm\n",
    "import lightgbm as lgb\n",
    "#catboost\n",
    "import catboost as ctb\n",
    "#xgboost\n",
    "import xgboost as xgb\n",
    "import matplotlib as mpl\n",
    "\n",
    "#Neural network\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data_without_prefs_and_with_HAMADA_factors.csv')\n",
    "data_ret = pd.read_csv('data_ret.csv')\n",
    "data_ret.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "#data_ret.set_index('Date', inplace=True)\n",
    "data.set_index('Date', inplace = True)\n",
    "macro_data = pd.read_csv('macro_data.csv')\n",
    "macro_data.set_index('Date', inplace = True)\n",
    "\n",
    "ml_results_best_params = pd.read_csv('ML_best_params_ever.csv')\n",
    "ml_data_1 = pd.read_csv('MSE_result_ever.csv')\n",
    "ml_data = pd.read_csv('R2_result_ever.csv')\n",
    "\n",
    "ml_data.set_index('share', inplace=True)\n",
    "ml_data_1.set_index('share', inplace=True)\n",
    "ml_results_best_params.set_index('share', inplace=True)\n",
    "\n",
    "# Подгрузим данные\n",
    "df = pd.read_csv('russian_data_without_prefs.csv')\n",
    "\n",
    "# Удалим все дни где дневная доходность всех бумаг равна нулю (праздники и выходные)\n",
    "df.drop(df[df.filter(regex='return_').sum(axis = 1) == 0].index, axis=0, inplace=True)\n",
    "df.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_autolag_return_30 = 30\n",
    "lag_autolag_return_60 = 60\n",
    "lag_autolag_return_90 = 90\n",
    "lag_30 = 30\n",
    "lag_60 = 60\n",
    "lag_90 = 90\n",
    "\n",
    "\n",
    "Long_returns_lasso = []\n",
    "Short_returns_lasso = []\n",
    "\n",
    "Long_10_lasso = []\n",
    "Short_10_lasso = []\n",
    "Hold_lasso = []\n",
    "\n",
    "\n",
    "window = 29\n",
    "gap_10 = 0.01\n",
    "\n",
    "for name in data_ret.columns[2:].drop(['return_PLZL_RM_Equity', 'return_RSTI_RM_Equity','return_MSRS_RM_Equity']):\n",
    "\n",
    "    df1 = data[[name, 'Hamada_beta_MRP_for_{}'.format(name[7:11]), 'risk_free_rate_based_on_g_curve',\n",
    "                 'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "                 'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]),\n",
    "                 'MOM']].dropna()\n",
    "    df_autolag = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)})\n",
    "    df_autolag = pd.DataFrame(df_autolag['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)].shift(lag_autolag_return_30).dropna())\n",
    "\n",
    "    df_autolag_2 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)})\n",
    "    df_autolag_2 = pd.DataFrame(df_autolag_2['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)].shift(lag_autolag_return_60).dropna())\n",
    "\n",
    "    df_autolag_3 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)})\n",
    "    df_autolag_3 = pd.DataFrame(df_autolag_3['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)].shift(lag_autolag_return_90).dropna())\n",
    "\n",
    "    df2 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_30).dropna()\n",
    "\n",
    "\n",
    "\n",
    "    df2.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_30)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([df1, df2], axis=1, join=\"inner\")\n",
    "\n",
    "    df3 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_60).dropna()\n",
    "\n",
    "    df3.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_60)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df3], axis=1, join=\"inner\")\n",
    "\n",
    "    df4 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_90).dropna()\n",
    "\n",
    "    df4.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_90)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df4], axis=1, join=\"inner\")\n",
    "\n",
    "    result = pd.merge(result, macro_data, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_2, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_3, left_index=True, right_index=True)\n",
    "    result['{}_Equity_premium'.format(name[7:14])] = result[name] - result['risk_free_rate_based_on_g_curve']\n",
    "\n",
    "    share = '{}_Equity_premium'.format(name[7:14])\n",
    "\n",
    "    dta = result.dropna()\n",
    "\n",
    "    X_train = dta.loc[:'2017-01-30',:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    X_test = dta.loc['2017-01-30':,:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    y_train = dta.loc[:'2017-01-30',:][share]\n",
    "    y_test = dta.loc['2017-01-30':,:][share]\n",
    "\n",
    "    lasso = Lasso(alpha = ast.literal_eval(ml_results_best_params.loc[share,'LASSO_best_params'])['alpha'],\n",
    "                  normalize=ast.literal_eval(ml_results_best_params.loc[share,'LASSO_best_params'])['normalize'],\n",
    "                  tol=ast.literal_eval(ml_results_best_params.loc[share,'LASSO_best_params'])['tol'])\n",
    "\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred_1 = lasso.predict(X_train.iloc[-1:])\n",
    "\n",
    "    # фактическая больше модельной\n",
    "    if y_train[-1] -  y_pred_1 > gap_10:\n",
    "        Short_10_lasso.append(name)\n",
    "    # модельная больше фактической\n",
    "    elif y_pred_1 - y_train[-1] > gap_10:\n",
    "        Long_10_lasso.append(name)\n",
    "    elif abs(y_pred_1 - y_train[-1]) < gap_10:\n",
    "            Hold_lasso.append(name)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "Recomends_lasso = pd.DataFrame({'Short':pd.Series(Short_10_lasso), \n",
    "                                  'Hold':pd.Series(Hold_lasso),\n",
    "                                  'Long':pd.Series(Long_10_lasso)})\n",
    "\n",
    "Recomends_lasso['Short'] = Recomends_lasso['Short'].astype(str).str[7:11]\n",
    "Recomends_lasso['Hold'] = Recomends_lasso['Hold'].astype(str).str[7:11]\n",
    "Recomends_lasso['Long'] = Recomends_lasso['Long'].astype(str).str[7:11]\n",
    "Recomends_lasso.to_excel('Great_recom_bear_lasso.xlsx', sheet_name='recom')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_autolag_return_30 = 30\n",
    "lag_autolag_return_60 = 60\n",
    "lag_autolag_return_90 = 90\n",
    "lag_30 = 30\n",
    "lag_60 = 60\n",
    "lag_90 = 90\n",
    "\n",
    "\n",
    "Long_returns_capm = []\n",
    "Short_returns_capm = []\n",
    "\n",
    "Long_10_capm = []\n",
    "Short_10_capm = []\n",
    "Hold_capm = []\n",
    "\n",
    "window = 29\n",
    "gap_10 = 0.01\n",
    "\n",
    "for name in data_ret.columns[2:].drop(['return_PLZL_RM_Equity', 'return_RSTI_RM_Equity','return_MSRS_RM_Equity']):\n",
    "\n",
    "    df1 = data[[name, 'Hamada_beta_MRP_for_{}'.format(name[7:11]), 'risk_free_rate_based_on_g_curve',\n",
    "                 'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "                 'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]),\n",
    "                 'MOM']].dropna()\n",
    "    df_autolag = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)})\n",
    "    df_autolag = pd.DataFrame(df_autolag['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)].shift(lag_autolag_return_30).dropna())\n",
    "\n",
    "    df_autolag_2 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)})\n",
    "    df_autolag_2 = pd.DataFrame(df_autolag_2['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)].shift(lag_autolag_return_60).dropna())\n",
    "\n",
    "    df_autolag_3 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)})\n",
    "    df_autolag_3 = pd.DataFrame(df_autolag_3['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)].shift(lag_autolag_return_90).dropna())\n",
    "\n",
    "    df2 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_30).dropna()\n",
    "\n",
    "\n",
    "\n",
    "    df2.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_30)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([df1, df2], axis=1, join=\"inner\")\n",
    "\n",
    "    df3 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_60).dropna()\n",
    "\n",
    "    df3.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_60)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df3], axis=1, join=\"inner\")\n",
    "\n",
    "    df4 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_90).dropna()\n",
    "\n",
    "    df4.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_90)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df4], axis=1, join=\"inner\")\n",
    "\n",
    "    result = pd.merge(result, macro_data, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_2, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_3, left_index=True, right_index=True)\n",
    "    result['{}_Equity_premium'.format(name[7:14])] = result[name] - result['risk_free_rate_based_on_g_curve']\n",
    "\n",
    "    share = '{}_Equity_premium'.format(name[7:14])\n",
    "\n",
    "    dta = result.dropna()\n",
    "\n",
    "    X_train = dta.loc[:'2017-01-30',:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    X_test = dta.loc['2017-01-30':,:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    y_train = dta.loc[:'2017-01-30',:][share]\n",
    "    y_test = dta.loc['2017-01-30':,:][share]\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train.iloc[:,0:1], y_train)\n",
    "\n",
    "    y_pred_1 = model.predict(X_train.iloc[-1:,0:1])\n",
    "\n",
    "    # фактическая больше модельной\n",
    "    if y_train[-1] -  y_pred_1 > gap_10:\n",
    "        Short_10_capm.append(name)\n",
    "    # модельная больше фактической\n",
    "    elif y_pred_1 - y_train[-1] > gap_10:\n",
    "        Long_10_capm.append(name)\n",
    "    elif abs(y_pred_1 - y_train[-1]) < gap_10:\n",
    "        Hold_capm.append(name)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Recomends_capm = pd.DataFrame({'Short':pd.Series(Short_10_capm), \n",
    "                                  'Hold':pd.Series(Hold_capm),\n",
    "                                  'Long':pd.Series(Long_10_capm)})\n",
    "\n",
    "Recomends_capm['Short'] = Recomends_capm['Short'].astype(str).str[7:11]\n",
    "Recomends_capm['Hold'] = Recomends_capm['Hold'].astype(str).str[7:11]\n",
    "Recomends_capm['Long'] = Recomends_capm['Long'].astype(str).str[7:11]\n",
    "Recomends_capm.to_excel('Great_recom_bear_capm.xlsx', sheet_name='recom')\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fama-French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_autolag_return_30 = 30\n",
    "lag_autolag_return_60 = 60\n",
    "lag_autolag_return_90 = 90\n",
    "lag_30 = 30\n",
    "lag_60 = 60\n",
    "lag_90 = 90\n",
    "\n",
    "\n",
    "Long_returns_ff = []\n",
    "Short_returns_ff = []\n",
    "\n",
    "Long_10_ff = []\n",
    "Short_10_ff = []\n",
    "Hold_ff = []\n",
    "\n",
    "window = 29\n",
    "gap_10 = 0.01\n",
    "\n",
    "for name in data_ret.columns[2:].drop(['return_PLZL_RM_Equity', 'return_RSTI_RM_Equity','return_MSRS_RM_Equity']):\n",
    "\n",
    "    df1 = data[[name, 'Hamada_beta_MRP_for_{}'.format(name[7:11]), 'risk_free_rate_based_on_g_curve',\n",
    "                 'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "                 'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]),\n",
    "                 'MOM']].dropna()\n",
    "    df_autolag = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)})\n",
    "    df_autolag = pd.DataFrame(df_autolag['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_30)].shift(lag_autolag_return_30).dropna())\n",
    "\n",
    "    df_autolag_2 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)})\n",
    "    df_autolag_2 = pd.DataFrame(df_autolag_2['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_60)].shift(lag_autolag_return_60).dropna())\n",
    "\n",
    "    df_autolag_3 = pd.DataFrame(data[name] - data['risk_free_rate_based_on_g_curve']).rename(columns = {0:'{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)})\n",
    "    df_autolag_3 = pd.DataFrame(df_autolag_3['{}_premium_lag_{}_days'.format(name[7:], lag_autolag_return_90)].shift(lag_autolag_return_90).dropna())\n",
    "\n",
    "    df2 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_30).dropna()\n",
    "\n",
    "\n",
    "\n",
    "    df2.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_30)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([df1, df2], axis=1, join=\"inner\")\n",
    "\n",
    "    df3 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_60).dropna()\n",
    "\n",
    "    df3.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_60)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df3], axis=1, join=\"inner\")\n",
    "\n",
    "    df4 = data[['Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "            'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), 'MOM']].shift(lag_90).dropna()\n",
    "\n",
    "    df4.rename(columns = {'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "                          'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]):'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90), \n",
    "                          'MOM':'MOM_lag_{}_days'.format(lag_90)}, inplace = True)\n",
    "\n",
    "    result = pd.concat([result, df4], axis=1, join=\"inner\")\n",
    "\n",
    "    result = pd.merge(result, macro_data, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_2, left_index=True, right_index=True)\n",
    "    result = pd.merge(result, df_autolag_3, left_index=True, right_index=True)\n",
    "    result['{}_Equity_premium'.format(name[7:14])] = result[name] - result['risk_free_rate_based_on_g_curve']\n",
    "\n",
    "    share = '{}_Equity_premium'.format(name[7:14])\n",
    "\n",
    "    dta = result.dropna()\n",
    "\n",
    "    X_train = dta.loc[:'2017-01-30',:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    X_test = dta.loc['2017-01-30':,:][['Hamada_beta_MRP_for_{}'.format(name[7:11]),\n",
    "       '{}_premium_lag_{}_days'.format(name[7:], lag_30),\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}'.format(name[7:11]),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}'.format(name[7:11]), \n",
    "       'MOM',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_30),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_30), \n",
    "       'MOM_lag_30_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_60),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_60), \n",
    "       'MOM_lag_60_days',\n",
    "       'Hamada_d_mcap_ratio_SMB_for_{}_lag_{}_days'.format(name[7:11], lag_90),\n",
    "       'Hamada_d_mcap_ratio_HML_for_{}_lag_{}_days'.format(name[7:11], lag_90),  \n",
    "       'MOM_lag_90_days',\n",
    "       'dollar_30d_return', 'wti_30d_return']]\n",
    "    y_train = dta.loc[:'2017-01-30',:][share]\n",
    "    y_test = dta.loc['2017-01-30':,:][share]\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train.iloc[:,[0, 2, 3]], y_train)\n",
    "\n",
    "    y_pred_1 = model.predict(X_train.iloc[-1:,[0, 2, 3]])\n",
    "\n",
    "    # фактическая больше модельной\n",
    "    if y_train[-1] -  y_pred_1 > gap_10:\n",
    "        Short_10_ff.append(name)\n",
    "    # модельная больше фактической\n",
    "    elif y_pred_1 - y_train[-1] > gap_10:\n",
    "        Long_10_ff.append(name)\n",
    "    elif abs(y_pred_1 - y_train[-1]) < gap_10:\n",
    "        Hold_ff.append(name)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "        \n",
    "Recomends_FF = pd.DataFrame({'Short':pd.Series(Short_10_ff), \n",
    "                                  'Hold':pd.Series(Hold_ff),\n",
    "                                  'Long':pd.Series(Long_10_ff)})\n",
    "        \n",
    "Recomends_FF['Short'] = Recomends_FF['Short'].astype(str).str[7:11]\n",
    "Recomends_FF['Hold'] = Recomends_FF['Hold'].astype(str).str[7:11]\n",
    "Recomends_FF['Long'] = Recomends_FF['Long'].astype(str).str[7:11]\n",
    "\n",
    "Recomends_FF.to_excel('Great_recom_bear_ff.xlsx', sheet_name='Рекомы_Фама_Френч')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
